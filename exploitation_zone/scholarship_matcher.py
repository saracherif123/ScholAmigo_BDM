import os
import streamlit as st
from dotenv import load_dotenv
from PIL import Image
import google.generativeai as genai
from pdf2image import convert_from_path
import pytesseract
import pdfplumber
import numpy as np
from sentence_transformers import SentenceTransformer
import json
import pickle
import psycopg2
import faiss
from typing import List, Dict, Any

# Load environment variables
load_dotenv()

# Configure Google Gemini AI
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Database connection
def get_db_connection():
    """Create a connection to the PostgreSQL database"""
    return psycopg2.connect(
        host=os.getenv("DB_HOST"),
        database=os.getenv("DB_NAME"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD")
    )

# Initialize sentence transformer model
@st.cache_resource
def load_embedding_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

# Load FAISS index and metadata
@st.cache_resource
def load_vector_db():
    """Load FAISS index and metadata"""
    # Get the absolute path to the vector_database directory
    current_dir = os.path.dirname(os.path.abspath(__file__))
    index_path = os.path.join(current_dir, "vector_database", "cv_index.faiss")
    metadata_path = os.path.join(current_dir, "vector_database", "cv_metadata.json")
    
    # Load the index and metadata
    index = faiss.read_index(index_path)
    with open(metadata_path, 'r') as f:
        metadata = json.load(f)
    
    return index, metadata

# Function to extract text from PDF
def extract_text_from_pdf(pdf_path):
    """Extract text from PDF using multiple methods for better accuracy"""
    text = ""
    
    # Try pdfplumber first
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                text += page.extract_text() or ""
    except Exception as e:
        print(f"Error with pdfplumber: {e}")
    
    # If text is empty or too short, try OCR
    if len(text.strip()) < 100:
        try:
            # Convert PDF to images
            images = convert_from_path(pdf_path)
            
            # Extract text from each image
            for image in images:
                text += pytesseract.image_to_string(image) + "\n"
        except Exception as e:
            print(f"Error with OCR: {e}")
    
    return text

# Function to analyze CV
def analyze_cv(resume_text):
    model = genai.GenerativeModel("gemini-1.5-flash")
    
    prompt = f"""
    You are an expert CV reviewer. Analyze the following CV and provide a detailed review in the following format:
    
    1. Overall Score (0-100)
    2. Strengths
    3. Areas for Improvement
    4. Key Skills Identified
    5. Education Level
    6. Years of Experience
    7. Industry/Field
    8. Recommendations for Enhancement
    
    CV:
    {resume_text}
    """
    
    try:
        response = model.generate_content(prompt)
        if not response or not response.text:
            return "No response from Gemini model"
        return response.text
    except Exception as e:
        return f"Failed to get analysis: {str(e)}"

# Function to match CV with scholarship
def match_cv_with_scholarship(resume_text, scholarship_name):
    model = genai.GenerativeModel("gemini-1.5-flash")
    
    prompt = f"""
    You are an expert scholarship advisor. Analyze how well the following CV matches with the scholarship: {scholarship_name}
    
    CV:
    {resume_text}
    
    Provide a detailed analysis in the following format:
    1. Match Score (0-100)
    2. Key Matching Points
    3. Missing Requirements
    4. Recommendations to Improve Match
    5. Overall Assessment
    
    Format your response as a JSON object with the following structure:
    {{
        "match_score": 85,
        "matching_points": ["Point 1", "Point 2", ...],
        "missing_requirements": ["Requirement 1", "Requirement 2", ...],
        "improvement_recommendations": ["Recommendation 1", "Recommendation 2", ...],
        "overall_assessment": "Detailed assessment text"
    }}
    """
    
    response = model.generate_content(prompt)
    try:
        return json.loads(response.text)
    except:
        return {"error": "Failed to parse match analysis", "raw_text": response.text}

# Function to find similar CVs
def find_similar_cvs(resume_text, model, index, metadata, top_k=5):
    # Create embedding for resume
    resume_embedding = model.encode([resume_text])[0]
    query_embedding = resume_embedding.reshape(1, -1).astype('float32')
    
    # Search in FAISS index
    distances, indices = index.search(query_embedding, top_k)
    
    # Format results
    similar_cvs = []
    for i, idx in enumerate(indices[0]):
        if idx != -1:  # FAISS returns -1 for empty slots
            similar_cvs.append({
                'cv': metadata[str(idx)],
                'similarity_score': float(1 - distances[0][i])  # Convert distance to similarity score
            })
    
    return similar_cvs

def fetch_scholarships_from_json() -> List[Dict[str, Any]]:
    """Fetch scholarships from local JSON file"""
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        json_path = os.path.join(current_dir, "data", "scholarships.json")
        
        with open(json_path, 'r') as f:
            scholarships = json.load(f)
        return scholarships
    except Exception as e:
        print(f"Error loading scholarships: {e}")
        # Return sample scholarships if file not found
        return [
            {
                "id": 1,
                "title": "Erasmus Mundus Joint Master's Scholarship",
                "description": "Fully funded scholarship for international students to study in multiple European countries.",
                "eligibility_criteria": "Bachelor's degree, English proficiency, academic excellence",
                "field_of_study": "Various fields",
                "level_of_study": "Master's",
                "country": "Multiple European countries",
                "application_deadline": "2024-12-31",
                "award_amount": "Full tuition + living expenses"
            },
            {
                "id": 2,
                "title": "Fulbright Foreign Student Program",
                "description": "Scholarship for international students to study in the United States.",
                "eligibility_criteria": "Bachelor's degree, English proficiency, leadership potential",
                "field_of_study": "All fields",
                "level_of_study": "Master's/PhD",
                "country": "United States",
                "application_deadline": "2024-10-15",
                "award_amount": "Full funding"
            }
        ]

def create_scholarship_embeddings(scholarships: List[Dict[str, Any]], model: SentenceTransformer) -> tuple:
    """Create embeddings for scholarships and build FAISS index"""
    # Prepare text for embedding
    scholarship_texts = []
    for scholarship in scholarships:
        text = f"""
        Title: {scholarship['title']}
        Description: {scholarship['description']}
        Eligibility: {scholarship['eligibility_criteria']}
        Field of Study: {scholarship['field_of_study']}
        Level of Study: {scholarship['level_of_study']}
        Country: {scholarship['country']}
        """
        scholarship_texts.append(text)
    
    # Create embeddings
    embeddings = model.encode(scholarship_texts)
    
    # Create FAISS index
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings.astype('float32'))
    
    return index, scholarships

def match_cv_with_scholarships(cv_text: str, model: SentenceTransformer, index: faiss.Index, 
                             scholarships: List[Dict[str, Any]], top_k: int = 5) -> List[Dict[str, Any]]:
    """Match CV with scholarships using semantic similarity"""
    # Create embedding for CV
    cv_embedding = model.encode([cv_text])[0]
    
    # Search in FAISS index
    cv_embedding = cv_embedding.reshape(1, -1).astype('float32')
    distances, indices = index.search(cv_embedding, top_k)
    
    # Prepare results
    matches = []
    for i, idx in enumerate(indices[0]):
        if idx != -1:  # FAISS returns -1 for empty slots
            similarity_score = float(1 - distances[0][i])  # Convert distance to similarity score
            scholarship = scholarships[idx]
            matches.append({
                'scholarship': scholarship,
                'similarity_score': similarity_score
            })
    
    return matches

def analyze_match(cv_text: str, scholarship: Dict[str, Any]) -> str:
    """Analyze how well the CV matches with a specific scholarship"""
    model = genai.GenerativeModel("gemini-1.5-flash")
    
    # Format scholarship details for better context
    scholarship_details = f"""
    Scholarship Details:
    Title: {scholarship.get('title', 'N/A')}
    Description: {scholarship.get('description', 'N/A')}
    Eligibility Criteria: {scholarship.get('eligibility_criteria', 'N/A')}
    Field of Study: {scholarship.get('field_of_study', 'N/A')}
    Level of Study: {scholarship.get('level_of_study', 'N/A')}
    Country: {scholarship.get('country', 'N/A')}
    Application Deadline: {scholarship.get('application_deadline', 'N/A')}
    Award Amount: {scholarship.get('award_amount', 'N/A')}
    """
    
    prompt = f"""
    You are an expert scholarship advisor. Analyze how well the following CV matches with this scholarship.
    
    {scholarship_details}
    
    CV:
    {cv_text}
    
    Provide a detailed analysis in the following format:
    1. Match Score (0-100)
    2. Key Matching Points
    3. Missing Requirements
    4. Recommendations to Improve Match
    5. Overall Assessment
    """
    
    try:
        response = model.generate_content(prompt)
        if not response or not response.text:
            return "No response from Gemini model"
        return response.text
    except Exception as e:
        return f"Failed to get analysis: {str(e)}"

# Streamlit app
st.set_page_config(page_title="Scholarship CV Matcher", layout="wide")

# Title
st.title("üéì Scholarship CV Matcher")
st.write("Upload your CV and find matching scholarships from our database!")

# Load models and data
embedding_model = load_embedding_model()
faiss_index, cv_metadata = load_vector_db()

# Fetch scholarships and create embeddings
with st.spinner("Loading scholarships..."):
    scholarships = fetch_scholarships_from_json()
    scholarship_index, scholarships = create_scholarship_embeddings(scholarships, embedding_model)

# File upload
uploaded_file = st.file_uploader("üìÑ Upload your CV (PDF)", type=["pdf"])

if uploaded_file is not None:
    # Save uploaded file
    with open("uploaded_cv.pdf", "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # Extract text
    resume_text = extract_text_from_pdf("uploaded_cv.pdf")
    
    # Create tabs
    tab1, tab2, tab3 = st.tabs(["üìù Resume Analysis", "üéØ Scholarship Matches", "üìä Detailed Analysis"])
    
    with tab1:
        if st.button("üîç Analyze Resume"):
            with st.spinner("Analyzing resume... ‚è≥"):
                try:
                    # Analyze resume
                    analysis = analyze_cv(resume_text)
                    st.success("‚úÖ Analysis complete!")
                    st.write(analysis)
                except Exception as e:
                    st.error(f"‚ùå Analysis failed: {str(e)}")
                    st.write("Please try again or check if the CV was properly uploaded.")

    with tab2:
        if st.button("üîç Find Matching Scholarships"):
            with st.spinner("Finding matching scholarships..."):
                matches = match_cv_with_scholarships(resume_text, embedding_model, scholarship_index, scholarships)
                
                for i, match in enumerate(matches, 1):
                    scholarship = match['scholarship']
                    similarity = match['similarity_score']
                    
                    with st.expander(f"{i}. {scholarship['title']} (Match: {similarity:.2%})"):
                        st.write(f"**Description:** {scholarship['description']}")
                        st.write(f"**Eligibility:** {scholarship['eligibility_criteria']}")
                        st.write(f"**Field of Study:** {scholarship['field_of_study']}")
                        st.write(f"**Level of Study:** {scholarship['level_of_study']}")
                        st.write(f"**Country:** {scholarship['country']}")
                        st.write(f"**Application Deadline:** {scholarship['application_deadline']}")
                        st.write(f"**Award Amount:** {scholarship['award_amount']}")
    
    with tab3:
        if st.button("üìä Analyze Top Match"):
            with st.spinner("Analyzing best match..."):
                try:
                    matches = match_cv_with_scholarships(resume_text, embedding_model, scholarship_index, scholarships, top_k=1)
                    if matches:
                        best_match = matches[0]
                        st.write("Analyzing match with:", best_match['scholarship']['title'])
                        analysis = analyze_match(resume_text, best_match['scholarship'])
                        st.success("‚úÖ Analysis complete!")
                        st.write(analysis)
                    else:
                        st.warning("No matching scholarships found.")
                except Exception as e:
                    st.error(f"‚ùå Analysis failed: {str(e)}")
                    st.write("Please try again or check if the CV was properly uploaded.")

# Footer
st.markdown("---")
st.markdown(
    """
    <style>
        .footer {
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
            text-align: center;
            padding: 10px;
            font-size: 14px;
        }
    </style>
    <div class="footer">
        üöÄ Powered by Streamlit and <a href="https://console.cloud.google.com/marketplace/product/google/gemini-ai" target="_blank">Google Gemini AI</a>
    </div>
    """,
    unsafe_allow_html=True) 