# # Exploitation Zone Erasmus Scholarships Data

# ### Step 1: Install and Import Required Libraries

# Install required packages (run this in a cell if not already installed)
# !pip install pyspark psycopg2-binary country_converter boto3


from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *
import country_converter as coco
import json
from datetime import datetime
import psycopg2
from psycopg2.extras import execute_values
import boto3
import pandas as p
import os
from time import sleep
print("All libraries imported successfully!")


aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID')
aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY')


# Initialize Spark Session
spark = SparkSession.builder \
    .appName("ErasmusScholarshipsTransformer") \
    .config("spark.jars", "postgresql-42.6.0.jar") \
    .config("spark.hadoop.fs.s3a.aws.credentials.provider", "org.apache.hadoop.fs.s3a.DefaultAWSCredentialsProviderChain") \
    .config("spark.hadoop.fs.s3a.access.key", aws_access_key_id) \
    .config("spark.hadoop.fs.s3a.secret.key", aws_secret_access_key) \
    .config("spark.jars.packages", "org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.665") \
    .config("spark.hadoop.fs.s3a.endpoint", "s3.amazonaws.com") \
    .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
    .config("spark.hadoop.fs.s3a.aws.credentials.provider", "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider") \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.driver.maxResultSize", "1g") \
    .getOrCreate()


spark.sparkContext.setLogLevel("WARN")  # Or "ERROR" for fewer logs

# Configuration


S3_BUCKET = "scholamigo"
S3_PREFIX = "trusted_zone_data/erasmus_data/"


S3_KEY_erasmus = f"s3a://{S3_BUCKET}/{S3_PREFIX}clean_erasmus.parquet"

POSTGRES_CONFIG = {
    "host": "localhost",
    "database": "ScholAmigo",
    "user": "marwasulaiman", #change to your username
    # "password": "your-password",
    "port": 5432
}


# Test PostgreSQL connection
try:
    test_conn = psycopg2.connect(**POSTGRES_CONFIG)
    test_conn.close()
    print("PostgreSQL connection successful!")
except Exception as e:
    print(f"PostgreSQL connection failed: {e}")


# ### Step 4: Test S3 Connection and Read Sample Data


# Test reading the parquet file from S3
try:
    df_erasmus = spark.read.parquet(f"{S3_KEY_erasmus}")
    print(f"Successfully read parquet file from S3!")
    print(f"Total records: {df_erasmus.count()}")
    print(f"Schema: {df_erasmus.columns}")
    
    # # Show first few rows
    # print("\nFirst 2 rows:")
    # df.show(2, truncate=False)
    
except Exception as e:
    print(f"Failed to read from S3: {e}")
    # For testing, you can also read from local file
    # df = spark.read.parquet("local_path_to_your_file.parquet")


# Check how many records have scholarship_available_for_current_intake = true
def check_available_scholarships(df):
    available_count = 0
    total_count = 0
    
    for row in df.collect():
        total_count += 1
        row_dict = row.asDict()
        
        clean_erasmus = row_dict.get('clean_erasmus_scholarship', {}).asDict()
        if clean_erasmus.get('scholarship_available_for_current_intake', False):
            available_count += 1
    
    print(f"Total records: {total_count}")
    print(f"Available scholarships: {available_count}")
    print(f"Filtered out: {total_count - available_count}")
    
    return available_count, total_count

available_count, total_count = check_available_scholarships(df_erasmus)


# ### Step 6: Setup Database Connection and Helper Functions


class ErasmusTransformer:

    FIELDS_OF_STUDY = {
        0: "Generic programmes and qualifications",
        1: "Education",
        2: "Arts and humanities",
        3: "Social sciences, journalism and information",
        4: "Business, administration and law",
        5: "Natural sciences, mathematics and statistics",
        6: "Information and Communication Technologies",
        7: "Engineering, manufacturing and construction",
        8: "Agriculture, forestry, fisheries and veterinary",
        9: "Health and welfare",
        10: "Services"
    }

    def __init__(self):
        self.conn = psycopg2.connect(**POSTGRES_CONFIG)
        self.cursor = self.conn.cursor()
        print("✅ Database connection established!")

    def truncate_tables(self):
        self.cursor.execute("""
            DO
            $$
            DECLARE
                r RECORD;
            BEGIN
                FOR r IN (
                    SELECT tablename
                    FROM pg_tables
                    WHERE schemaname = 'public'
                )
                LOOP
                    EXECUTE format(
                        'TRUNCATE TABLE public.%I RESTART IDENTITY CASCADE;',
                        r.tablename
                    );
                END LOOP;
            END;
            $$;
        """)
        self.conn.commit()
        print("Tables truncated successfully!")

    def get_countries_data(self):
        """Get all countries using country_converter"""
        cc = coco.CountryConverter()
        all_countries = cc.data[['name_short']].drop_duplicates().reset_index(drop=True)
        return all_countries['name_short'].tolist()
    
    def populate_countries(self):
        try:
            # Start a new transaction
            self.conn.rollback()  # Rollback any failed transaction


            """Populate countries table in alphabetical order with sequential keys"""
            countries = self.get_countries_data()
            countries = sorted(set(countries))  # sort and remove duplicates if needed
            print(f"Found {len(countries)} unique sorted countries")
            
            # Insert countries
            country_data = [(country,) for country in countries]
            execute_values(
                self.cursor,
                "INSERT INTO countries (name) VALUES %s ON CONFLICT (name) DO NOTHING",
                country_data
            )
            self.conn.commit()
            print("Countries populated successfully!")
            
            # Get country key mapping ordered by key
            self.cursor.execute("SELECT key, name FROM countries ORDER BY key")
            country_mapping = {name: key for key, name in self.cursor.fetchall()}
            print(f"Country mapping created with {len(country_mapping)} entries")
            return country_mapping
        except Exception as e:
            print(f"Error in populate_countries: {str(e)}")
            self.conn.rollback()
            raise e

    def get_field_key_mapping(self):
        # """Get field of study key mapping"""
        # field_mapping = {
        #     "Generic programmes and qualifications": 0,
        #     "Education": 1,
        #     "Arts and humanities": 2,
        #     "Social sciences, journalism and information": 3,
        #     "Business, administration and law": 4,
        #     "Natural sciences, mathematics and statistics": 5,
        #     "Information and Communication Technologies": 6,
        #     "Engineering, manufacturing and construction": 7,
        #     "Agriculture, forestry, fisheries and veterinary": 8,
        #     "Health and welfare": 9,
        #     "Services": 10
        # }
        # return field_mapping
    
        return {v: k for k, v in self.FIELDS_OF_STUDY.items()}

    def populate_fields_of_study(self):
        try:
            self.conn.rollback()  # rollback any pending transactions

            # Prepare the static data list (key, field)
            fields_of_study_data = [(key, field) for key, field in self.FIELDS_OF_STUDY.items()]

            # Insert with ON CONFLICT DO NOTHING to avoid duplicates if rerun
            execute_values(
                self.cursor,
                """
                INSERT INTO fields_of_study (key, field) VALUES %s
                ON CONFLICT (key) DO NOTHING
                """,
                fields_of_study_data
            )
            self.conn.commit()
            print("✅ Fields of study populated successfully!")

        except Exception as e:
            print(f"Error in populate_fields_of_study: {str(e)}")
            self.conn.rollback()
            raise e

    
    def parse_date(self, date_str):
        """Parse date string to datetime object"""
        try:
            return datetime.strptime(date_str, "%d/%m/%Y").date()
        except:
            return None
    
    def close_connection(self):
        self.cursor.close()
        self.conn.close()
        print("Database connection closed!")

# Initialize instance
exp = ErasmusTransformer()

# ### Step 7: Populate Countries Table

# Truncate all tables
exp.truncate_tables()

# Populate countries and get mapping
print("Populating countries...")
country_mapping = exp.populate_countries()
exp.populate_fields_of_study()

# Show some sample country mappings
print("\nSample country mappings:")
for i, (country, key) in enumerate(list(country_mapping.items())[:10]):
    print(f"{key}: {country}")

# ### Step 9: Complete Processing Function (Updated)


def process_scholarship_data_complete(row_data, country_mapping, field_mapping, exp_instance):
    """Complete processing function for a single scholarship record"""
    
    try:
        # Start a new transaction
        exp_instance.conn.rollback()  # Rollback any failed transaction
        
        extracted = row_data.get('extracted', {}).asDict()
        
        # Handle JSON string (keeping original logic as fallback)
        if isinstance(extracted, str):
            extracted = json.loads(extracted)
        
        # Validate scholarship name
        name = row_data.get('clean_scholarship_name', 'N/A')
        if not name or name == "N/A" or len(name) < 3:
            return None
        
        # Skip if scholarship not available for current intake
        clean_erasmus = row_data.get('clean_erasmus_scholarship', {}).asDict()
        if not clean_erasmus.get('scholarship_available_for_current_intake', False):
            return None
        
        # Insert into scholarships_common
        intake_map = {'fall': 'Fall', 'spring': 'Spring'}
        status_map = {'open': 'Open', 'closed': 'Closed'}
        
        intake = intake_map.get(row_data.get('clean_admission', '').lower())
        status = status_map.get(row_data.get('clean_status', '').lower())
        
        # Dynamic funding type extraction
        funding = extracted.get('scholarship_type', '').lower()
        if "full" in funding:
            funding = "Full"
        elif "partial" in funding:
            funding = "Partial"
        else:
            funding = "Unknown"
        
        exp_instance.cursor.execute("""
            INSERT INTO scholarships_common (funding, name, level, required_level, intake, status)
            VALUES (%s, %s, %s, %s, %s, %s) RETURNING key
        """, (funding, name, 'Master', 'Bachelor', intake, status))
        
        sch_key = exp_instance.cursor.fetchone()[0]
        print(f"✅ Inserted into scholarships_common with key: {sch_key} and name: {name}")
        # sleep(3)

        
        # Process scholarships_erasmus
        description = row_data.get('clean_description', '')
        duration = float(row_data.get('clean_duration', 0)) if row_data.get('clean_duration') else 0.0
        available_intake = clean_erasmus.get('scholarship_available_for_current_intake', False)
        scholarship_comments = clean_erasmus.get('comments', '')

        required_docs = extracted.get('required_documents', '')
        course_topics = ', '.join(extracted.get('course_topics', [])) if extracted.get('course_topics') else ''
        courses_link = extracted.get('courses_details_link', '')
        deadlines_link = extracted.get('deadlines_more_details_link', '')
        mobility_link = extracted.get('mobility_structure_details_link', '')
        scholarship_more_details_link = extracted.get('scholarship_more_details_link', '')

        other_scholarships = extracted.get('other_scholarships', '')

        url = row_data.get('url', '')
        
        requirements = extracted.get('requirements', {}).asDict()
        # if hasattr(requirements, 'asDict'):
        #     requirements = requirements.asDict()
        requirements_link = requirements.get('requirements_more_details_link', '') if requirements else ''
        requirements_str = json.dumps(requirements) if requirements else ''
        
        # others = ', '.join(extracted.get('Other', [])) if extracted.get('Other') else ''

        others = ', '.join(s.rstrip('.') for s in extracted.get('Other', [])) if extracted.get('Other') else ''

        # Erasmus scholarship financial details
        prog_countries = clean_erasmus.get('programme_countries', {}).asDict()
        partner_countries = clean_erasmus.get('partner_countries', {}).asDict()
        
        # # Handle nested dictionaries that might need asDict()
        # if hasattr(prog_countries, 'asDict'):
        #     prog_countries = prog_countries.asDict()
        # if hasattr(partner_countries, 'asDict'):
        #     partner_countries = partner_countries.asDict()
        
        exp_instance.cursor.execute("""
            INSERT INTO scholarships_erasmus (
                key, name, url, scholarship_comments, description, duration, scholarship_available_for_current_intake,
                required_documents, course_topics, courses_details_link, deadlines_more_details_link,
                other_scholarships, requirements_more_details_link, requirements, others,
                programme_tuition_cov, programme_tuition_details, programme_monthly_allowance, 
                programme_installation_costs, partner_tuition_cov, partner_tuition_details,
                partner_monthly_allowance, partner_installation_costs, mobility_link, scholarship_more_details_link
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            sch_key, name, url, scholarship_comments, description, duration, available_intake,
            required_docs, course_topics, courses_link, deadlines_link,
            other_scholarships, requirements_link, requirements_str, others,
            str(prog_countries.get('tuition_coverage', '')),
            prog_countries.get('tuition_coverage_details', ''),
            str(prog_countries.get('monthly_allowance', '')),
            prog_countries.get('installation_costs', ''),
            str(partner_countries.get('tuition_coverage', '')),
            partner_countries.get('tuition_coverage_details', ''),
            str(partner_countries.get('monthly_allowance', '')),
            partner_countries.get('installation_costs', ''),
            mobility_link, scholarship_more_details_link
        ))
        
        # Process fields of study
        fields_of_study = extracted.get('fields_of_study', [])
        for field in fields_of_study:
            if field in field_mapping:
                exp_instance.cursor.execute("""
                    INSERT INTO scholarships_fields (sch_key, field_key) VALUES (%s, %s)
                """, (sch_key, field_mapping[field]))
        
        # Process origin countries
        nationality = requirements.get('nationality', '') if requirements else ''
        if nationality == 'All':
            # Add all countries
            for country_key in country_mapping.values():
                exp_instance.cursor.execute("""
                    INSERT INTO origin_countries_sch (sch_key, country_key) VALUES (%s, %s)
                """, (sch_key, country_key))
        elif isinstance(nationality, list):
            # Add specific countries
            for country_name in nationality:
                if country_name in country_mapping:
                    exp_instance.cursor.execute("""
                        INSERT INTO origin_countries_sch (sch_key, country_key) VALUES (%s, %s)
                    """, (sch_key, country_mapping[country_name]))
        
        # Process program countries
        clean_countries = row_data.get('clean_countries', [])
        for country_name in clean_countries:
            if country_name in country_mapping:
                exp_instance.cursor.execute("""
                    INSERT INTO program_countries_sch (sch_key, country_key) VALUES (%s, %s)
                """, (sch_key, country_mapping[country_name]))
        
        # # Process universities
        # clean_universities = row_data.get('clean_universities', [])
        # for uni_data in clean_universities:
        #     # Handle if uni_data has asDict method
        #     uni_data = uni_data.asDict()   
        #     # if hasattr(uni_data, 'asDict'):
        #     #     uni_data = uni_data.asDict()
            
        #     uni_name = uni_data.get('name', '')
        #     uni_country = uni_data.get('country', '')
            
        #     if uni_country in country_mapping:
        #         # Insert university if not exists
        #         exp_instance.cursor.execute("""
        #             INSERT INTO universities (university, country_key) 
        #             VALUES (%s, %s) 
        #             ON CONFLICT (university, country_key) DO NOTHING
        #         """, (uni_name, country_mapping[uni_country]))
                
        #         # Get university key
        #         exp_instance.cursor.execute("""
        #             SELECT key FROM universities WHERE university = %s AND country_key = %s
        #         """, (uni_name, country_mapping[uni_country]))
                
        #         result = exp_instance.cursor.fetchone()
        #         if result:
        #             uni_key = result[0]
                    
        #             # Link scholarship to university
        #             exp_instance.cursor.execute("""
        #                 INSERT INTO sch_uni (sch_key, uni_key) VALUES (%s, %s)
        #             """, (sch_key, uni_key))
        
        # Process universities
        clean_universities = row_data.get('clean_universities', [])
        for uni_data in clean_universities:
            # Handle if uni_data has asDict method
            if hasattr(uni_data, 'asDict'):
                uni_data = uni_data.asDict()
            
            uni_name = uni_data.get('name', '')
            uni_country = uni_data.get('country', '')
            
            if uni_country in country_mapping and uni_name.strip():
                try:
                    # Insert university if not exists - without ON CONFLICT
                    exp_instance.cursor.execute("""
                        SELECT key FROM universities WHERE university = %s AND country_key = %s
                    """, (uni_name, country_mapping[uni_country]))
                    
                    result = exp_instance.cursor.fetchone()
                    if result:
                        uni_key = result[0]
                    else:
                        # Insert new university
                        exp_instance.cursor.execute("""
                            INSERT INTO universities (university, country_key) 
                            VALUES (%s, %s) RETURNING key
                        """, (uni_name, country_mapping[uni_country]))
                        uni_key = exp_instance.cursor.fetchone()[0]
                    
                    # Link scholarship to university
                    exp_instance.cursor.execute("""
                        INSERT INTO sch_uni (sch_key, uni_key) VALUES (%s, %s)
                    """, (sch_key, uni_key))
                except Exception as uni_error:
                    print(f"Warning: Could not process university {uni_name}: {str(uni_error)}")
                    continue
        


        # Process important dates and deadlines
        important_dates = row_data.get('clean_important_dates', [])
        for date_info in important_dates:
            # Handle if date_info has asDict method
            if hasattr(date_info, 'asDict'):
                date_info = date_info.asDict()
            
            date_obj = exp_instance.parse_date(date_info.get('date', ''))
            description = date_info.get('description', '')
            comments = date_info.get('comments', '')
            
            if date_obj:
                if 'deadline' in description.lower():
                    # Insert into deadlines table
                    exp_instance.cursor.execute("""
                        INSERT INTO deadlines (sch_key, date, description, comments)
                        VALUES (%s, %s, %s, %s)
                    """, (sch_key, date_obj, description, comments))
                else:
                    # Insert into important_dates table
                    exp_instance.cursor.execute("""
                        INSERT INTO important_dates (sch_key, date, description, comments)
                        VALUES (%s, %s, %s, %s)
                    """, (sch_key, date_obj, description, comments))
        
        return sch_key
        
    except Exception as e:
        exp_instance.conn.rollback()
        print(f"Error processing scholarship '{name}': {str(e)}")
        return None

print("✅ Updated complete processing function defined!")

# ### Step 10: Process All Data (Updated)


# Process all available scholarships
print("Starting full data processing...")

field_mapping = exp.get_field_key_mapping()


try:
    rows = df_erasmus.collect()
    processed_count = 0
    skipped_count = 0
    error_count = 0
    
    for i, row in enumerate(rows):
        row_dict = row.asDict()
        
        result = process_scholarship_data_complete(row_dict, country_mapping, field_mapping, exp)
        
        if result:
            processed_count += 1
            exp.conn.commit()
            # if processed_count % 5 == 0:  # Commit every 5 records for testing
            #     # exp.conn.commit()
            #     print(f"Processed {processed_count} scholarships (committed)...")
        elif result is None:
            skipped_count += 1
        else:
            error_count += 1
        
        # Show progress
        if (i + 1) % 10 == 0:
            print(f"Progress: {i + 1}/{len(rows)} rows processed. Accepted: {processed_count}, Skipped: {skipped_count}, Errors: {error_count}")
    
    # Final commit
    exp.conn.commit()
    print(f"\nPosrgres Process completed successfully!")
    print(f"Total processed: {processed_count}")
    print(f"Total skipped: {skipped_count}")
    print(f"Total errors: {error_count}")
    print(f"Total rows: {len(rows)}")
    
except Exception as e:
    print(f"Error during processing: {str(e)}")
    exp.conn.rollback()
    raise


#%%

def parse_duration(duration_str):
    """Parse duration string to float, return None if not a valid number"""
    try:
        if duration_str and duration_str.replace('.', '').isdigit():
            return float(duration_str)
        return None
    except:
        return None

def process_uk_scholarship_data(row_data, country_mapping, field_mapping, exp_instance):
    """Processing function for UK scholarship records"""
    
    try:
        # Start a new transaction
        exp_instance.conn.rollback()  # Rollback any failed transaction
        
        extracted = row_data.get('extracted', {}).asDict()
        
        # Handle JSON string (keeping original logic as fallback)
        if isinstance(extracted, str):
            extracted = json.loads(extracted)
        
        # Validate scholarship name
        name = row_data.get('clean_scholarship_name', 'N/A')
        if not name or name == "N/A" or len(name) < 3:
            return None
        
        # Skip if scholarship not available for current intake
        clean_scholarship = row_data.get('clean_scholarship', {}).asDict()
        if not clean_scholarship.get('scholarship_available_for_current_intake', False):
            return None
        
        # Insert into scholarships_common
        intake_map = {'fall': 'Fall', 'spring': 'Spring'}
        status_map = {'open': 'Open', 'closed': 'Closed'}
        
        intake = intake_map.get(row_data.get('clean_admission', '').lower())
        status = status_map.get(row_data.get('clean_status', '').lower())
        
        # Dynamic funding type extraction
        funding = extracted.get('scholarship_type', '').lower()
        if "full" in funding:
            funding = "Full"
        elif "partial" in funding:
            funding = "Partial"
        else:
            funding = "Unknown"
        
        level = extracted.get('level', '')

        if level.lower() == 'bachelor':
            required_level = 'High School'
        elif level.lower() == 'master':
            required_level = 'Bachelor'
        else:
            required_level = 'Unknown'

        exp_instance.cursor.execute("""
            INSERT INTO scholarships_common (funding, name, level, required_level, intake, status)
            VALUES (%s, %s, %s, %s, %s, %s) RETURNING key
        """, (funding, name, level, required_level, intake, status))
        
        sch_key = exp_instance.cursor.fetchone()[0]
        print(f"✅ Inserted into scholarships_common with key: {sch_key} and name: {name}")
        
        # Process scholarships_other
        description = row_data.get('clean_description', '')
        duration = parse_duration(row_data.get('clean_duration', ''))
        available_intake = clean_scholarship.get('scholarship_available_for_current_intake', True)
        scholarship_comments = clean_scholarship.get('comments', '')

        required_docs = extracted.get('required_documents', '')
        course_topics = ', '.join(extracted.get('course_topics', [])) if extracted.get('course_topics') else ''
        courses_link = extracted.get('courses_details_link', '')
        deadlines_link = extracted.get('deadlines_more_details_link', '')
        scholarship_more_details_link = extracted.get('scholarship_more_details_link', '')

        other_scholarships = extracted.get('other_scholarships', '')
        url = row_data.get('url', '')
        
        requirements = extracted.get('requirements', {}).asDict()
        requirements_link = requirements.get('requirements_more_details_link', '') if requirements else ''
        requirements_str = json.dumps(requirements) if requirements else ''
        
        others = ', '.join(s.rstrip('.') for s in extracted.get('Other', [])) if extracted.get('Other') else ''

        # UK scholarship financial details
        tuition_cov = clean_scholarship.get('tuition_coverage', '')
        tuition_details = clean_scholarship.get('tuition_coverage_details', '')
        monthly_allowance = clean_scholarship.get('monthly_allowance', '')
        installation_costs = clean_scholarship.get('installation_costs', '')
        
        exp_instance.cursor.execute("""
            INSERT INTO scholarships_other (
                key, name, url, description, duration, scholarship_available_for_current_intake,
                required_documents, course_topics, courses_details_link, deadlines_more_details_link,
                scholarship_more_details_link, other_scholarships, requirements_more_details_link, 
                requirements, others, scholarship_comments, tuition_cov, tuition_details, 
                monthly_allowance, installation_costs
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            sch_key, name, url, description, duration, available_intake,
            required_docs, course_topics, courses_link, deadlines_link,
            scholarship_more_details_link, other_scholarships, requirements_link, 
            requirements_str, others, scholarship_comments, str(tuition_cov), 
            tuition_details, str(monthly_allowance), installation_costs
        ))
        
        # Process fields of study
        fields_of_study = extracted.get('fields_of_study', [])
        for field in fields_of_study:
            if field in field_mapping:
                exp_instance.cursor.execute("""
                    INSERT INTO scholarships_fields (sch_key, field_key) VALUES (%s, %s)
                """, (sch_key, field_mapping[field]))
        
        # Process origin countries
        nationality = requirements.get('nationality', '') if requirements else ''
        if nationality == 'All':
            # Add all countries
            for country_key in country_mapping.values():
                exp_instance.cursor.execute("""
                    INSERT INTO origin_countries_sch (sch_key, country_key) VALUES (%s, %s)
                """, (sch_key, country_key))
        elif isinstance(nationality, list):
            # Add specific countries
            for country_name in nationality:
                if country_name in country_mapping:
                    exp_instance.cursor.execute("""
                        INSERT INTO origin_countries_sch (sch_key, country_key) VALUES (%s, %s)
                    """, (sch_key, country_mapping[country_name]))
        
        # Process program countries - add United Kingdom for all UK scholarships
        if 'United Kingdom' in country_mapping:
            exp_instance.cursor.execute("""
                INSERT INTO program_countries_sch (sch_key, country_key) VALUES (%s, %s)
            """, (sch_key, country_mapping['United Kingdom']))
        
        # Process universities
        clean_universities = row_data.get('clean_universities', [])
        for uni_data in clean_universities:
            if hasattr(uni_data, 'asDict'):
                uni_data = uni_data.asDict()
            
            uni_name = uni_data.get('name', '')
            uni_country = uni_data.get('country', '')
            
            if uni_country in country_mapping and uni_name.strip():
                try:
                    exp_instance.cursor.execute("""
                        SELECT key FROM universities WHERE university = %s AND country_key = %s
                    """, (uni_name, country_mapping[uni_country]))
                    
                    result = exp_instance.cursor.fetchone()
                    if result:
                        uni_key = result[0]
                    else:
                        exp_instance.cursor.execute("""
                            INSERT INTO universities (university, country_key) 
                            VALUES (%s, %s) RETURNING key
                        """, (uni_name, country_mapping[uni_country]))
                        uni_key = exp_instance.cursor.fetchone()[0]
                    
                    exp_instance.cursor.execute("""
                        INSERT INTO sch_uni (sch_key, uni_key) VALUES (%s, %s)
                    """, (sch_key, uni_key))
                except Exception as uni_error:
                    print(f"Warning: Could not process university {uni_name}: {str(uni_error)}")
                    continue

        # Process important dates and deadlines
        important_dates = row_data.get('clean_important_dates', [])
        for date_info in important_dates:
            if hasattr(date_info, 'asDict'):
                date_info = date_info.asDict()
            
            date_obj = exp_instance.parse_date(date_info.get('date', ''))
            description = date_info.get('description', '')
            comments = date_info.get('comments', '')
            
            if date_obj:
                if 'deadline' in description.lower():
                    exp_instance.cursor.execute("""
                        INSERT INTO deadlines (sch_key, date, description, comments)
                        VALUES (%s, %s, %s, %s)
                    """, (sch_key, date_obj, description, comments))
                else:
                    exp_instance.cursor.execute("""
                        INSERT INTO important_dates (sch_key, date, description, comments)
                        VALUES (%s, %s, %s, %s)
                    """, (sch_key, date_obj, description, comments))
        
        return sch_key
        
    except Exception as e:
        exp_instance.conn.rollback()
        print(f"Error processing UK scholarship '{name}': {str(e)}")
        return None


S3_BUCKET = "scholamigo"
S3_PREFIX = "trusted_zone_data/uk_data/"

S3_KEY_uk = f"s3a://{S3_BUCKET}/{S3_PREFIX}clean_uk.parquet"


try:
    df_uk = spark.read.parquet(f"{S3_KEY_uk}")
    print(f"Successfully read parquet file from S3!")
    print(f"Total records: {df_uk.count()}")
    print(f"Schema: {df_uk.columns}")
    
    # # Show first few rows
    # print("\nFirst 2 rows:")
    # df.show(2, truncate=False)
    
except Exception as e:
    print(f"Failed to read from S3: {e}")
    # For testing, you can also read from local file
    # df = spark.read.parquet("local_path_to_your_file.parquet")


# Process all available scholarships
print("Starting full data processing...")

field_mapping = exp.get_field_key_mapping()

try:
    rows = df_uk.collect()
    processed_count = 0
    skipped_count = 0
    error_count = 0
    
    for i, row in enumerate(rows):
        row_dict = row.asDict()
        
        result = process_uk_scholarship_data(row_dict, country_mapping, field_mapping, exp)

        if result:
            processed_count += 1
            exp.conn.commit()
        elif result is None:
            skipped_count += 1
        else:
            error_count += 1
        
        # Show progress
        if (i + 1) % 10 == 0:
            print(f"UK Progress: {i + 1}/{len(rows)} rows processed. Accepted: {processed_count}, Skipped: {skipped_count}, Errors: {error_count}")
    
    # Final commit
    exp.conn.commit()
    print(f"\nUK Postgres Process completed successfully!")
    print(f"Total processed: {processed_count}")
    print(f"Total skipped: {skipped_count}")
    print(f"Total errors: {error_count}")
    print(f"Total rows: {len(rows)}")
    
except Exception as e:
    print(f"Error during processing: {str(e)}")
    exp.conn.rollback()
    raise


# ### Step 11: Verify Data in Database


# Check the data in the database
def verify_data(exp_instance):
    print("Verifying data in database...")
    
    # Check scholarships_common
    exp_instance.cursor.execute("SELECT COUNT(*) FROM scholarships_common")
    sch_count = exp_instance.cursor.fetchone()[0]
    print(f"Scholarships in scholarships_common: {sch_count}")
    
    # Check scholarships_erasmus
    exp_instance.cursor.execute("SELECT COUNT(*) FROM scholarships_erasmus")
    erasmus_count = exp_instance.cursor.fetchone()[0]
    print(f"Scholarships in scholarships_erasmus: {erasmus_count}")
    
    # Check countries
    exp_instance.cursor.execute("SELECT COUNT(*) FROM countries")
    country_count = exp_instance.cursor.fetchone()[0]
    print(f"Countries: {country_count}")
    
    # Check universities
    exp_instance.cursor.execute("SELECT COUNT(*) FROM universities")
    uni_count = exp_instance.cursor.fetchone()[0]
    print(f"Universities: {uni_count}")
    
    # Check important dates and deadlines
    exp_instance.cursor.execute("SELECT COUNT(*) FROM important_dates")
    dates_count = exp_instance.cursor.fetchone()[0]
    print(f"Important dates: {dates_count}")
    
    exp_instance.cursor.execute("SELECT COUNT(*) FROM deadlines")
    deadlines_count = exp_instance.cursor.fetchone()[0]
    print(f"Deadlines: {deadlines_count}")
    
    # Sample scholarship data
    exp_instance.cursor.execute("""
        SELECT sc.key, se.name, sc.intake, sc.status 
        FROM scholarships_common sc 
        JOIN scholarships_erasmus se ON sc.key = se.key 
        LIMIT 5
    """)
    
    print("\nSample scholarships:")
    for row in exp_instance.cursor.fetchall():
        print(f"ID: {row[0]}, Name: {row[1]}, Intake: {row[2]}, Status: {row[3]}")

verify_data(exp)

# ### Step 12: Cleanup

# Close connections
exp.close_connection()
spark.stop()
print("All connections closed. Process completed!")